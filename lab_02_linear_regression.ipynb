{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "lab-02_linear_regression.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hiroykim/colab/blob/master/lab_02_linear_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Y8Xe34kKFJ4",
        "colab_type": "text"
      },
      "source": [
        "# Lab 2: Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJT1ss4kKFJ5",
        "colab_type": "text"
      },
      "source": [
        "Author: Seungjae Lee (이승재)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZomF5vJ1KFJ6",
        "colab_type": "text"
      },
      "source": [
        "<div class=\"alert alert-warning\">\n",
        "    We use elemental PyTorch to implement linear regression here. However, in most actual applications, abstractions such as <code>nn.Module</code> or <code>nn.Linear</code> are used.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZgqZNz9KFJ6",
        "colab_type": "text"
      },
      "source": [
        "## Theoretical Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZ7z-AicKFJ7",
        "colab_type": "text"
      },
      "source": [
        "$$ H(x) = Wx + b $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xe2n5AOBKFJ7",
        "colab_type": "text"
      },
      "source": [
        "$$ cost(W, b) = \\frac{1}{m} \\sum^m_{i=1} \\left( H(x^{(i)}) - y^{(i)} \\right)^2 $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Omy1uk-0KFJ7",
        "colab_type": "text"
      },
      "source": [
        " - $H(x)$: 주어진 $x$ 값에 대해 예측을 어떻게 할 것인가\n",
        " - $cost(W, b)$: $H(x)$ 가 $y$ 를 얼마나 잘 예측했는가"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82bdoLF5KFJ8",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCmO73eEKFJ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xROr-FvjKFKB",
        "colab_type": "code",
        "colab": {},
        "outputId": "c599b879-e4a1-4701-db13-6f041228fbaa"
      },
      "source": [
        "# For reproducibility\n",
        "torch.manual_seed(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fa29837ef90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4wbgWVBKFKD",
        "colab_type": "text"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uknlSk6EKFKE",
        "colab_type": "text"
      },
      "source": [
        "We will use fake data for this example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MXnwm_YKFKE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = torch.FloatTensor([[1], [2], [3]])\n",
        "y_train = torch.FloatTensor([[1], [2], [3]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sjhr323KFKG",
        "colab_type": "code",
        "colab": {},
        "outputId": "7e63b5fd-73ba-41d3-d072-84f4a2e87fcf"
      },
      "source": [
        "print(x_train)\n",
        "print(x_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1.],\n",
            "        [2.],\n",
            "        [3.]])\n",
            "torch.Size([3, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDxKH0E9KFKI",
        "colab_type": "code",
        "colab": {},
        "outputId": "82f03065-e40f-4887-98c5-22eff1e0bda6"
      },
      "source": [
        "print(y_train)\n",
        "print(y_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1.],\n",
            "        [2.],\n",
            "        [3.]])\n",
            "torch.Size([3, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53sSAo7EKFKL",
        "colab_type": "text"
      },
      "source": [
        "기본적으로 PyTorch는 NCHW 형태이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zeniMmrKFKL",
        "colab_type": "text"
      },
      "source": [
        "## Weight Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wR4zqtM_KFKM",
        "colab_type": "code",
        "colab": {},
        "outputId": "673b8fa9-3f5a-422c-b9d0-4f8cc481585f"
      },
      "source": [
        "W = torch.zeros(1, requires_grad=True)\n",
        "print(W)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCqH6vlPKFKP",
        "colab_type": "code",
        "colab": {},
        "outputId": "5e829700-cf79-4c99-e470-6c96dec27972"
      },
      "source": [
        "b = torch.zeros(1, requires_grad=True)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQIQt-XtKFKR",
        "colab_type": "text"
      },
      "source": [
        "## Hypothesis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbPPrhEHKFKR",
        "colab_type": "text"
      },
      "source": [
        "$$ H(x) = Wx + b $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hlR9rgDKFKS",
        "colab_type": "code",
        "colab": {},
        "outputId": "45782fe4-d335-401f-9bb0-8338dcf453e2"
      },
      "source": [
        "hypothesis = x_train * W + b\n",
        "print(hypothesis)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.],\n",
            "        [0.],\n",
            "        [0.]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ltuf8SatKFKT",
        "colab_type": "text"
      },
      "source": [
        "## Cost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jthlsGFGKFKU",
        "colab_type": "text"
      },
      "source": [
        "$$ cost(W, b) = \\frac{1}{m} \\sum^m_{i=1} \\left( H(x^{(i)}) - y^{(i)} \\right)^2 $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PDck2MHKFKU",
        "colab_type": "code",
        "colab": {},
        "outputId": "52b7f7e2-668d-4ddb-d106-1b7a015bb862"
      },
      "source": [
        "print(hypothesis)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.],\n",
            "        [0.],\n",
            "        [0.]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZW7GS7vJKFKX",
        "colab_type": "code",
        "colab": {},
        "outputId": "7126eb4e-383c-4773-db6e-514005823a12"
      },
      "source": [
        "print(y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1.],\n",
            "        [2.],\n",
            "        [3.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QS6okm0IKFKZ",
        "colab_type": "code",
        "colab": {},
        "outputId": "7f9e48f6-ea7e-4ecc-e70e-0d3dd926540a"
      },
      "source": [
        "print(hypothesis - y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-1.],\n",
            "        [-2.],\n",
            "        [-3.]], grad_fn=<SubBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvdwSczBKFKb",
        "colab_type": "code",
        "colab": {},
        "outputId": "fbfbba4d-eb72-41a9-8cdf-451b74deb254"
      },
      "source": [
        "print((hypothesis - y_train) ** 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1.],\n",
            "        [4.],\n",
            "        [9.]], grad_fn=<PowBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6YyWjrbKFKd",
        "colab_type": "code",
        "colab": {},
        "outputId": "d9b7b75a-10e9-4819-fde1-f90dc34039b9"
      },
      "source": [
        "cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "print(cost)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(4.6667, grad_fn=<MeanBackward1>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Mq65h_MKFKf",
        "colab_type": "text"
      },
      "source": [
        "## Gradient Descent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2U_ZQ3dXKFKg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.SGD([W, b], lr=0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuVAwArdKFKi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer.zero_grad()\n",
        "cost.backward()\n",
        "optimizer.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3l_qxFBpKFKk",
        "colab_type": "code",
        "colab": {},
        "outputId": "c92b1d96-d333-4545-ef63-2fc7c5e387c6"
      },
      "source": [
        "print(W)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.0933], requires_grad=True)\n",
            "tensor([0.0400], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypfFwikIKFKm",
        "colab_type": "text"
      },
      "source": [
        "Let's check if the hypothesis is now better."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ha0WOTj8KFKn",
        "colab_type": "code",
        "colab": {},
        "outputId": "0b479bb8-4968-4913-9d91-d0098e865d93"
      },
      "source": [
        "hypothesis = x_train * W + b\n",
        "print(hypothesis)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.1333],\n",
            "        [0.2267],\n",
            "        [0.3200]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wef_tyHfKFKp",
        "colab_type": "code",
        "colab": {},
        "outputId": "45558563-9d30-439a-cd99-38805430504f"
      },
      "source": [
        "cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "print(cost)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(3.6927, grad_fn=<MeanBackward1>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZePJ0RQfKFKq",
        "colab_type": "text"
      },
      "source": [
        "## Training with Full Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwyTKAcqKFKr",
        "colab_type": "text"
      },
      "source": [
        "In reality, we will be training on the dataset for multiple epochs. This can be done simply with loops."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RudsadvQKFKr",
        "colab_type": "code",
        "colab": {},
        "outputId": "551fd9e8-9655-4873-cbc3-22638a7c6eba"
      },
      "source": [
        "# 데이터\n",
        "x_train = torch.FloatTensor([[1], [2], [3]])\n",
        "y_train = torch.FloatTensor([[1], [2], [3]])\n",
        "# 모델 초기화\n",
        "W = torch.zeros(1, requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "# optimizer 설정\n",
        "optimizer = optim.SGD([W, b], lr=0.01)\n",
        "\n",
        "nb_epochs = 1000\n",
        "for epoch in range(nb_epochs + 1):\n",
        "    \n",
        "    # H(x) 계산\n",
        "    hypothesis = x_train * W + b\n",
        "    \n",
        "    # cost 계산\n",
        "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 100번마다 로그 출력\n",
        "    if epoch % 100 == 0:\n",
        "        print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(\n",
        "            epoch, nb_epochs, W.item(), b.item(), cost.item()\n",
        "        ))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch    0/1000 W: 0.093, b: 0.040 Cost: 4.666667\n",
            "Epoch  100/1000 W: 0.873, b: 0.289 Cost: 0.012043\n",
            "Epoch  200/1000 W: 0.900, b: 0.227 Cost: 0.007442\n",
            "Epoch  300/1000 W: 0.921, b: 0.179 Cost: 0.004598\n",
            "Epoch  400/1000 W: 0.938, b: 0.140 Cost: 0.002842\n",
            "Epoch  500/1000 W: 0.951, b: 0.110 Cost: 0.001756\n",
            "Epoch  600/1000 W: 0.962, b: 0.087 Cost: 0.001085\n",
            "Epoch  700/1000 W: 0.970, b: 0.068 Cost: 0.000670\n",
            "Epoch  800/1000 W: 0.976, b: 0.054 Cost: 0.000414\n",
            "Epoch  900/1000 W: 0.981, b: 0.042 Cost: 0.000256\n",
            "Epoch 1000/1000 W: 0.985, b: 0.033 Cost: 0.000158\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h59Tl9IaKFKs",
        "colab_type": "text"
      },
      "source": [
        "## High-level Implementation with `nn.Module`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaWBL-HqKFKt",
        "colab_type": "text"
      },
      "source": [
        "Remember that we had this fake data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hE4rVN1KFKt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = torch.FloatTensor([[1], [2], [3]])\n",
        "y_train = torch.FloatTensor([[1], [2], [3]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4-c89vPKFKv",
        "colab_type": "text"
      },
      "source": [
        "이제 linear regression 모델을 만들면 되는데, 기본적으로 PyTorch의 모든 모델은 제공되는 `nn.Module`을 inherit 해서 만들게 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omn97TgLKFKv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LinearRegressionModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BdlDOWfKFKy",
        "colab_type": "text"
      },
      "source": [
        "모델의 `__init__`에서는 사용할 레이어들을 정의하게 됩니다. 여기서 우리는 linear regression 모델을 만들기 때문에, `nn.Linear` 를 이용할 것입니다. 그리고 `forward`에서는 이 모델이 어떻게 입력값에서 출력값을 계산하는지 알려줍니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JigGuQ_MKFKy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = LinearRegressionModel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MglGgw-hKFK0",
        "colab_type": "text"
      },
      "source": [
        "## Hypothesis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hl6dmdm2KFK0",
        "colab_type": "text"
      },
      "source": [
        "이제 모델을 생성해서 예측값 $H(x)$를 구해보자"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OkblHFCKFK0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hypothesis = model(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XckBVAU4KFK2",
        "colab_type": "code",
        "colab": {},
        "outputId": "7f3597c4-369e-40be-fd31-5ee9f2f8690b"
      },
      "source": [
        "print(hypothesis)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.0739],\n",
            "        [0.5891],\n",
            "        [1.1044]], grad_fn=<ThAddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3-180YGKFK3",
        "colab_type": "text"
      },
      "source": [
        "## Cost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5snUZ0gKFK4",
        "colab_type": "text"
      },
      "source": [
        "이제 mean squared error (MSE) 로 cost를 구해보자. MSE 역시 PyTorch에서 기본적으로 제공한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awpvtUviKFK4",
        "colab_type": "code",
        "colab": {},
        "outputId": "e9ca8b9a-7bba-4260-d0ad-ae3ba6556804"
      },
      "source": [
        "print(hypothesis)\n",
        "print(y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.0739],\n",
            "        [0.5891],\n",
            "        [1.1044]], grad_fn=<ThAddmmBackward>)\n",
            "tensor([[1.],\n",
            "        [2.],\n",
            "        [3.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMTAuxEvKFK6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cost = F.mse_loss(hypothesis, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KugsQsgKFK8",
        "colab_type": "code",
        "colab": {},
        "outputId": "f2701c5d-3740-462f-a913-f442b75ff1b1"
      },
      "source": [
        "print(cost)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.1471, grad_fn=<MseLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCdHl4X5KFK9",
        "colab_type": "text"
      },
      "source": [
        "## Gradient Descent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XnPxtVgKFK-",
        "colab_type": "text"
      },
      "source": [
        "마지막 주어진 cost를 이용해 $H(x)$ 의 $W, b$ 를 바꾸어서 cost를 줄여봅니다. 이때 PyTorch의 `torch.optim` 에 있는 `optimizer` 들 중 하나를 사용할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mG2HzlRgKFK-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5L-TRhTaKFLA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer.zero_grad()\n",
        "cost.backward()\n",
        "optimizer.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Us7U1GQCKFLC",
        "colab_type": "text"
      },
      "source": [
        "## Training with Full Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9y8a9AWKFLC",
        "colab_type": "text"
      },
      "source": [
        "이제 Linear Regression 코드를 이해했으니, 실제로 코드를 돌려 피팅시켜보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_LDfeUDKFLD",
        "colab_type": "code",
        "colab": {},
        "outputId": "16fe28fd-b5c6-43f1-cf59-599469dca067"
      },
      "source": [
        "# 데이터\n",
        "x_train = torch.FloatTensor([[1], [2], [3]])\n",
        "y_train = torch.FloatTensor([[1], [2], [3]])\n",
        "# 모델 초기화\n",
        "model = LinearRegressionModel()\n",
        "# optimizer 설정\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "nb_epochs = 1000\n",
        "for epoch in range(nb_epochs + 1):\n",
        "    \n",
        "    # H(x) 계산\n",
        "    prediction = model(x_train)\n",
        "    \n",
        "    # cost 계산\n",
        "    cost = F.mse_loss(prediction, y_train)\n",
        "    \n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    # 100번마다 로그 출력\n",
        "    if epoch % 100 == 0:\n",
        "        params = list(model.parameters())\n",
        "        W = params[0].item()\n",
        "        b = params[1].item()\n",
        "        print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(\n",
        "            epoch, nb_epochs, W, b, cost.item()\n",
        "        ))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch    0/1000 W: -0.101, b: 0.508 Cost: 4.630286\n",
            "Epoch  100/1000 W: 0.713, b: 0.653 Cost: 0.061555\n",
            "Epoch  200/1000 W: 0.774, b: 0.514 Cost: 0.038037\n",
            "Epoch  300/1000 W: 0.822, b: 0.404 Cost: 0.023505\n",
            "Epoch  400/1000 W: 0.860, b: 0.317 Cost: 0.014525\n",
            "Epoch  500/1000 W: 0.890, b: 0.250 Cost: 0.008975\n",
            "Epoch  600/1000 W: 0.914, b: 0.196 Cost: 0.005546\n",
            "Epoch  700/1000 W: 0.932, b: 0.154 Cost: 0.003427\n",
            "Epoch  800/1000 W: 0.947, b: 0.121 Cost: 0.002118\n",
            "Epoch  900/1000 W: 0.958, b: 0.095 Cost: 0.001309\n",
            "Epoch 1000/1000 W: 0.967, b: 0.075 Cost: 0.000809\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8u3WJzlKFLE",
        "colab_type": "text"
      },
      "source": [
        "점점 $H(x)$ 의 $W$ 와 $b$ 를 조정해서 cost가 줄어드는 것을 볼 수 있습니다."
      ]
    }
  ]
}